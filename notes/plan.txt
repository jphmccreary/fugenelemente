~~generate DT for each year using jobimtext~~
    this will take so much work to figure out - let's start with the DT provided by Riedl&Biemann

generate splits by feeding into SECOS the two required inputs, repeating for each year
    - the sentences for a year
    - the dt ~~for a year~~

count the number of splits for each word

extract the compounds (we're considering GCWs to be the words with #splits > 0)

a sequence of data transformations are applied,
and the data is dumped in a series of yeared folders for each step in the process
    @ data_transformations/order.txt

determine Fugenelement
    thoughts:
        comparing to lemma alone won't work

count em sort em

analyze em

Question: how does using only 1 year of data in the DT (1M words as opposed to SECOS's 70M affect splitting performance metrics?)
    for now this will go unanswered as I have resigned to using the provided DT

Additional analysis:
    DO THIS: analyze subset where number of cooccurences of a word <1000
    counting frequency of certain words
    counting Fn that cooresponds to pluralization of modifiers as a single group
